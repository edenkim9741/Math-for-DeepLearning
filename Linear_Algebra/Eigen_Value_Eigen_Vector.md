# Definition of Eigen
eigen은 독일어로 고유한, 특징적인 이라는 의미를 가진 단어

# Determinant의 기하학적 의미
어떤 행렬 $A$의 Determinant의 기하학적 의미는 $A$가 선형변환으로 사용되었을 때, 변환 이후의 단위 면적(혹은 부피)이 변하는 비율을 의미함

## 그림으로 이해해보기
![](attachments/Pasted%20image%2020250408143456.png)

위와 같은 그림의 변환을 만드는 행렬 $A$가 있다고 가정하자. 이 때 이 행렬 $A$는 어떤 모습이고, 행렬식은 몇일까?

만약 Determinant의 기하학적 의미가 단위 면적(혹은 부피)의 변환 비율이라면, Determinant가 0이 된다는 것은 어떤 의미일까?


# 고유값과 고유벡터의 기하학적 이해
위 그림에서 우리는 1x1의 정사각형을 변환시키는 행렬 $A$를 보았다. 이 때 이 변환 이후에도 바뀌지 않는 벡터는 무엇일까?

그것은 $x$축과 평행한 벡터이다. 이것이 행렬 $A$의 고유벡터이다. 즉, 고유벡터는 변환 이후에도 바뀌지 않는 벡터를 의미함.

이는 우리가 흔히 알고 있는 $(A - \lambda I) \mathbf{x} = \mathbf{0}$의 해를 구하는 것과 같다. 

$\lambda I$는 크기 변환만을 의미한다. 위 식에서 $(A - \lambda I) \mathbf{x} = \mathbf{0}$의 해를 구하는 것은 크기만 변한 벡터는 무엇인지 구하는 것이다.

즉, $A$의 고유값과 고유벡터를 구하는 것과 같다.


어떤 변환을 거친 후에도 방향이 변하지 않는 것을 고유벡터라고 하고, 방향은 변하지 않았지만 크기는 변할 수 있기 때문에 크기의 변화율을 나타내는 것이 고유값이다.

(문제) $\theta \neq 0 \text{ or } 2\pi$ 인 $\theta$에 대한 2차원에서의 회전 변환을 생각해보자. 이 경우의 고유벡터는 무엇인가? 자신의 생각이 맞는지 수식으로 확인해보자.

# 일차 독립, 일차 종속의 기하학적 이해
## 일차 독립
일차 독립은 $n$개의 벡터가 서로 독립적이라는 의미로, $n$개의 벡터가 서로 선형 결합으로 표현될 수 없다는 것을 의미함. 즉, $n$개의 벡터가 서로 독립적이라면, 이 벡터들은 서로 다른 방향을 가리키고 있다는 것.
## 일차 종속
일차 종속은 $n$개의 벡터가 서로 종속적이라는 의미로, $n$개의 벡터가 서로 선형 결합으로 표현될 수 있다는 것을 의미함. 즉, $n$개의 벡터가 서로 종속적이라면, 이 벡터들은 서로 같은 방향을 가리키고 있다는 것.

이전 시간에 행렬은 벡터의 집합 정도로 표현될 수 있다고 하였음. 이 때 행렬을 이루는 열벡터들이 서로 독립적인지 종속적인지와 행렬식은 어떤 관계가 있을까?

추후에 살펴보겠지만, 선형 변환은 행렬곱을 통해 이루어짐. 지난 시간에 행렬곱은 내적 즉, 정사영의 과정이 포함되어 있다고 볼 수 있다고 하였음.

만약 열벡터들이 서로 독립적이라면, 변환 과정에서 임의의 벡터가 사영될 때 모두 독립적이라는 말과 같음. 즉, 차원이 줄어들지 않음. 반면 열벡터들 중에 종속인 벡터들이 있다는 것은, 임의의 벡터가 사영될 때, 종속인 벡터들로 사영된다는 말과 같음. 즉, 사영된 이후에 다른 벡터들의 선형결합으로 표현 가능하게되고, 이는 곧 차원이 줄어들었음을 의미함

차원이 줄어들게 되면 부피나 면적은 어떻게 될까? 차원이 줄어들게 되면 부피나 면적은 0이 될 것임. 즉, 차원이 줄어들게 되면 Determinant는 0이 될 것임. 즉, 열벡터들이 서로 독립적이라면 Determinant는 0이 아니고, 종속적이라면 Determinant는 0이 된다.

이 때 일차 독립인 열벡터의 수를 rank라고 함.

Low rank 행렬이라고하면 일차 종속인 열벡터 수가 많다 == 일차 독립인 열벡터 수가 적다.

보통 우리가 풀어야하는 문제는 Low rank인 경우가 많음. (CNN이나 MLP를 통해서 차원을 줄여주는 것과도 일맥 상통)




# PCA
인터넷에서 본 좋은 예
PCA는 성적을 잘 계산하는 방법

예를 들어 국어 수학 두 과목에 대한 평균 점수를 계산한다고 할 때, 국어가 수학보다 더 어려웠다고 한다면, 국어 점수에 더 가중치를 주는 것이 형평성에 맞을 것.

이를 벡터로 바라보면 어떤 학생의 성적 벡터에 국어 수학의 난이도에 따른 가중치 벡터를 내적한다고 볼 수 있음.
이는 곧 사영 하는 것임

좀 더 높은 차원으로 생각해보자.

어떤 데이터가 n차원에 분포해 있다고 하자. 이 때 PCA는 이 n차원 데이터의 분포를 잘 설명할 수 있는 k차원으로 차원을 줄이는 방법이다. 즉, n차원 데이터의 분포를 잘 설명할 수 있는 k차원으로 사영하는 방법이다.

이를 다르게 말하면 어떤 데이터가 주어졌을 때 이 데이터의 분산을 최대로 하는 차원으로 사영하는 것 과 같다.

PCA는 주로 covariance matrix를 사용하여 k차원으로 사영하는 방법을 찾음. 즉, PCA는 covariance matrix의 고유값 분해를 통해 k차원으로 사영하는 방법을 찾음.

## Covariance Matrix란?
Covariance Matrix는 데이터의 분산을 나타내는 행렬이다. 수식으로는 아래와 같다.
$$
Cov(X) = \frac{1}{n} \sum_{i=1}^{n} (X_i - \mu)(X_i - \mu)^T
$$

자 그런데 여기서, $(X_i - \mu)(X_i - \mu)^T$는 무엇일까? 이건 $X$의 행벡터가 데이터라고 할 때, 각 데이터 샘플 간의 유사도를 의미함.

또, Covariance Matrix의 각 원소에 대해서 살펴보면 대칭 행렬일 것임을 자연스레 알 수 있음.

통계적으로는 확률 변수들 간의 선형 관계를 나타내는 값임

통계적으로는 다른 방법으로 유도될 수 있지만, 그것은 통계에 대해 살펴볼 때 더 자세하게 설명.
지금은 Covariance Matrix가 데이터가 어떻게 퍼져있는지를 알려준다고 생각하자.

다시 PCA로 돌아가보자.

Covariance Matrix의 고유벡터는 무엇을 의미할까?

Covariance matrix의 고유벡터는 데이터가 가장 많이 퍼져있는 방향을 의미함.

데이터가 퍼진 모양을 타원이라고 생각하면 축들이 고유벡터가 된다고 생각하면 됨.

여기서 하나 알아야 할 것이 대칭행렬의 고유벡터가 가지는 특징이다.

(실수 대칭행렬의 고유값이 실수라는 것을 증명)
(문제) 대칭행렬의 고유벡터는 서로 직교한다는 것을 증명해보자. (힌트: 대칭행렬의 고유값은 실수이다)

그렇다면 고유값은? 고유값은 해당 고유벡터 방향으로 얼마나 커지는지를 의미함. 즉, 고유값이 클수록 해당 고유벡터 방향으로 데이터가 많이 퍼져있다는 것임.

즉, PCA는 고유값 분해를 통해 데이터가 가장 많이 퍼져있는 방향을 찾고, 이 방향으로 차원을 줄이는 방법이다.

자 그럼 맨 위에서 생각해본 간단한 선형 변환 행렬의 고유값을 다시 떠올려보자. 분명 x축의 벡터였는데, 이것은 마름모를 의미하는 벡터가 아닌것 같다. 왜 그럴까?

정답은 이 선형변환 행렬이 공분산행렬이 될 수 없기 때문임. 공분산 행렬은 대칭이어야하는데, 위의 행렬은 대칭이 아님.

이제 실제로 계산해보자

## PCA의 수식
$$
\mathbf{\Sigma} \mathbf{v} = \lambda \mathbf{v}
$$

$$
(\mathbf{\Sigma} - \lambda \mathbf{I}) \mathbf{v} = \mathbf{0}
$$

$\mathbf{v} \neq \mathbf{0}$ 이므로, $\mathbf{\Sigma} - \lambda \mathbf{I}$의 Determinant는 0이 되어야함

$$
\text{det}(\mathbf{\Sigma} - \lambda \mathbf{I}) = 0
$$

이 식은 하나의 고유값과 고유벡터를 구하는 식임. 여러개의 고유값과 고유벡터를 행렬 연산을 통해 한 번에 구해보자

$$
\mathbf{V} = \begin{bmatrix}
\mathbf{v_1} & \mathbf{v_2} & \cdots & \mathbf{v_n}
\end{bmatrix}
$$
이라고 하면

$$
\mathbf{\Sigma} \mathbf{V} = \mathbf{V} \mathbf{\Lambda}
$$

여기서 $\mathbf{\Sigma}$는 대칭행렬이므로 $\mathbf{V}$는 직교행렬이 된다. 뿐만 아니라 $\mathbf{\Lambda}$가 크기를 정규화해주는 대각행렬이므로 $\mathbf{V}$는 정규직교행렬이 된다. 즉, $\mathbf{V}^T \mathbf{V} = \mathbf{I}$가 성립한다.

(문제) 정규직교행렬은 왜 $\mathbf{V}^T \mathbf{V} = \mathbf{I}$가 성립하는지 증명해보자.


$$
\mathbf{\Sigma} \mathbf{V} \mathbf{V}^{-1} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^{-1}
$$

$$
\mathbf{\Sigma} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^{-1}
$$

$$
\mathbf{\Sigma} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^{T}
$$


이후에는 $\mathbf{\Lambda}$의 의 크기를 기준으로 정렬하여 가장 영향이 큰 고유벡터를 구하면 된다.